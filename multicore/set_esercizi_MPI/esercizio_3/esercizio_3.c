/*
1. You have a 2D matrix A, filled with random elements. The number of rows and columns can be different (get them from
command line through argv). The matrix is randomly generated by rank 0. After the matrix is generated, you perform a 
number of iterations (the number of iterations is also read through argv).
2. At each iteration s we compute a new matrix A, such that
A_s[i][j] = A_s-1[i-1][j] + A_s-1[i][j-1] + A_s-1[i+1][j] + A_s-1[i][j+1]

ATTENTION: do this by allocating no more than two matrices, regardless of the number of iterations you need to execute. also
manage the case where number of elements in the matrix is larger than the number of processes
*/